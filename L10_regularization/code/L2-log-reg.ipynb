{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 479: Deep Learning (Spring 2019)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat479-ss2019/  \n",
    "GitHub repository: https://github.com/rasbt/stat479-deep-learning-ss19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.7.1\n",
      "IPython 7.2.0\n",
      "\n",
      "torch 1.0.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Runs on CPU or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of *classic* logistic regression for binary class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "LAMBDA = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "### DATASET\n",
    "##########################\n",
    "\n",
    "data = np.genfromtxt('data/toydata.txt', delimiter='\\t')\n",
    "x = data[:, :2].astype(np.float32)\n",
    "y = data[:, 2].astype(np.int64)\n",
    "\n",
    "np.random.seed(123)\n",
    "idx = np.arange(y.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "X_test, y_test = x[idx[:25]], y[idx[:25]]\n",
    "X_train, y_train = x[idx[25:]], y[idx[25:]]\n",
    "mu, std = np.mean(X_train, axis=0), np.std(X_train, axis=0)\n",
    "X_train, X_test = (X_train - mu) / std, (X_test - mu) / std\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 2.5))\n",
    "ax[0].scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1])\n",
    "ax[0].scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1])\n",
    "ax[1].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1])\n",
    "ax[1].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1])\n",
    "plt.xlim([x[:, 0].min()-0.5, x[:, 0].max()+0.5])\n",
    "plt.ylim([x[:, 1].min()-0.5, x[:, 1].max()+0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-Regularized Logistic Regression via `weight_decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Train ACC: 0.973 | Cost: 0.055\n",
      "Epoch: 002 | Train ACC: 0.973 | Cost: 0.065\n",
      "Epoch: 003 | Train ACC: 0.973 | Cost: 0.080\n",
      "Epoch: 004 | Train ACC: 0.973 | Cost: 0.094\n",
      "Epoch: 005 | Train ACC: 0.973 | Cost: 0.104\n",
      "Epoch: 006 | Train ACC: 0.973 | Cost: 0.108\n",
      "Epoch: 007 | Train ACC: 0.973 | Cost: 0.110\n",
      "Epoch: 008 | Train ACC: 0.973 | Cost: 0.111\n",
      "Epoch: 009 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 010 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 011 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 012 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 013 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 014 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 015 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 016 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 017 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 018 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 019 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 020 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 021 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 022 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 023 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 024 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 025 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 026 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 027 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 028 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 029 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 030 | Train ACC: 0.973 | Cost: 0.112\n",
      "\n",
      "Model parameters:\n",
      "  Weights: Parameter containing:\n",
      "tensor([[1.7546, 1.5997]], requires_grad=True)\n",
      "  Bias: Parameter containing:\n",
      "tensor([-0.0401], requires_grad=True)\n",
      "\n",
      "\n",
      "Test set accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "def custom_where(cond, x_1, x_2):\n",
    "    return (cond * x_1) + ((1-cond) * x_2)\n",
    "\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(num_features, 1)\n",
    "        # initialize weights to zeros here,\n",
    "        # since we used zero weights in the\n",
    "        # manual approach\n",
    "        \n",
    "        self.linear.weight.detach().zero_()\n",
    "        self.linear.bias.detach().zero_()\n",
    "        # Note: the trailing underscore\n",
    "        # means \"in-place operation\" in the context\n",
    "        # of PyTorch\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return probas\n",
    "\n",
    "model = LogisticRegression(num_features=2).to(device)\n",
    "\n",
    "#########################################################\n",
    "## Apply L2 regularization\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=0.1, \n",
    "                            weight_decay=LAMBDA)\n",
    "#-------------------------------------------------------\n",
    "\n",
    "\n",
    "def comp_accuracy(label_var, pred_probas):\n",
    "    pred_labels = custom_where((pred_probas > 0.5).float(), 1, 0).view(-1)\n",
    "    acc = torch.sum(pred_labels == label_var.view(-1)).float() / label_var.size(0)\n",
    "    return acc\n",
    "\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #### Compute outputs ####\n",
    "    out = model(X_train_tensor)\n",
    "    \n",
    "    #### Compute gradients ####\n",
    "    cost = F.binary_cross_entropy(out, y_train_tensor, reduction='sum')\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    \n",
    "    #### Update weights ####  \n",
    "    optimizer.step()\n",
    "    \n",
    "    #### Logging ####      \n",
    "    pred_probas = model(X_train_tensor)\n",
    "    acc = comp_accuracy(y_train_tensor, pred_probas)\n",
    "    print('Epoch: %03d' % (epoch + 1), end=\"\")\n",
    "    print(' | Train ACC: %.3f' % acc, end=\"\")\n",
    "    print(' | Cost: %.3f' % F.binary_cross_entropy(pred_probas, y_train_tensor))\n",
    "\n",
    "\n",
    "    \n",
    "print('\\nModel parameters:')\n",
    "print('  Weights: %s' % model.linear.weight)\n",
    "print('  Bias: %s' % model.linear.bias)\n",
    "\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "pred_probas = model(X_test_tensor)\n",
    "test_acc = comp_accuracy(y_test_tensor, pred_probas)\n",
    "\n",
    "print('\\n\\nTest set accuracy: %.2f%%' % (test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-Regularized Logistic Regression via Manual Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Train ACC: 0.973 | Cost: 0.055\n",
      "Epoch: 002 | Train ACC: 0.973 | Cost: 0.065\n",
      "Epoch: 003 | Train ACC: 0.973 | Cost: 0.080\n",
      "Epoch: 004 | Train ACC: 0.973 | Cost: 0.094\n",
      "Epoch: 005 | Train ACC: 0.973 | Cost: 0.104\n",
      "Epoch: 006 | Train ACC: 0.973 | Cost: 0.108\n",
      "Epoch: 007 | Train ACC: 0.973 | Cost: 0.110\n",
      "Epoch: 008 | Train ACC: 0.973 | Cost: 0.111\n",
      "Epoch: 009 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 010 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 011 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 012 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 013 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 014 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 015 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 016 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 017 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 018 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 019 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 020 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 021 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 022 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 023 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 024 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 025 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 026 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 027 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 028 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 029 | Train ACC: 0.973 | Cost: 0.112\n",
      "Epoch: 030 | Train ACC: 0.973 | Cost: 0.112\n",
      "\n",
      "Model parameters:\n",
      "  Weights: Parameter containing:\n",
      "tensor([[1.7546, 1.5997]], requires_grad=True)\n",
      "  Bias: Parameter containing:\n",
      "tensor([-0.0401], requires_grad=True)\n",
      "\n",
      "\n",
      "Test set accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(num_features=2).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #### Compute outputs ####\n",
    "    out = model(X_train_tensor)\n",
    "    \n",
    "    #### Compute gradients ####\n",
    "    \n",
    "    #########################################################\n",
    "    ## Apply L2 regularization (weight decay)\n",
    "    cost = F.binary_cross_entropy(out, y_train_tensor, reduction='sum')\n",
    "    cost = cost + 0.5 * LAMBDA * torch.mm(model.linear.weight,\n",
    "                                          model.linear.weight.t())\n",
    "    \n",
    "    # note that PyTorch also regularizes the bias, hence, if we want\n",
    "    # to reproduce the behavior of SGD's \"weight_decay\" param, we have to add\n",
    "    # the bias term as well: \n",
    "    cost = cost + 0.5 * LAMBDA * model.linear.bias**2\n",
    "    #-------------------------------------------------------\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    \n",
    "    #### Update weights ####  \n",
    "    optimizer.step()\n",
    "    \n",
    "    #### Logging ####      \n",
    "    pred_probas = model(X_train_tensor)\n",
    "    acc = comp_accuracy(y_train_tensor, pred_probas)\n",
    "    print('Epoch: %03d' % (epoch + 1), end=\"\")\n",
    "    print(' | Train ACC: %.3f' % acc, end=\"\")\n",
    "    print(' | Cost: %.3f' % F.binary_cross_entropy(pred_probas, y_train_tensor))\n",
    "\n",
    "\n",
    "    \n",
    "print('\\nModel parameters:')\n",
    "print('  Weights: %s' % model.linear.weight)\n",
    "print('  Bias: %s' % model.linear.bias)\n",
    "\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "pred_probas = model(X_test_tensor)\n",
    "test_acc = comp_accuracy(y_test_tensor, pred_probas)\n",
    "\n",
    "print('\\n\\nTest set accuracy: %.2f%%' % (test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: for easier comparison we plotted the regular cost, not the regularized cost (strictly, plotting the regularized cost is more useful as the regular ost may not always go down while making \"progress\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
